{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the data-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 23:14:47.847424 140252623681344 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bf2c75fd4247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work2/EK100/modeling/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work2/EK100/models/builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfully_det\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFullyDet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweakly_det\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeaklyDet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_time\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSingleTimeDet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work2/EK100/models/fully_det.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection_evaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectionEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_process\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmasked_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work2/EK100/models/detection_evaluation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate_detection_json_ek100\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mANETdetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work2/EK100/C2-Action-Detection/EvaluationCode/evaluate_detection_json_ek100.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from google.protobuf import text_format\n",
    "from modeling import trainer\n",
    "from protos import model_pb2\n",
    "from protos import pipeline_pb2\n",
    "from readers import reader\n",
    "\n",
    "model_dir = \"logs/single_class_aware/\"\n",
    "video_lengths_csv = \"epic-kitchens-100-annotations/EPIC_100_video_info.csv\"\n",
    "verb_classes_csv = \"epic-kitchens-100-annotations/EPIC_100_verb_classes.csv\"\n",
    "noun_classes_csv = \"epic-kitchens-100-annotations/EPIC_100_noun_classes.csv\"\n",
    "\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "with tf.io.gfile.GFile(os.path.join(model_dir, 'pipeline.pbtxt'), 'r') as fp:\n",
    "  pipeline_proto = text_format.Merge(fp.read(), pipeline_pb2.Pipeline())\n",
    "\n",
    "# HERE WE VISUALIZE TRAIN SET PREDICTIONS.\n",
    "reader_options = pipeline_proto.train_reader\n",
    "reader_options.ek100_st_reader.batch_size = 1\n",
    "model_options = pipeline_proto.model.Extensions[model_pb2.SingleTimeClassAwareDet.ext]\n",
    "n_verb_classes = model_options.n_verb_classes\n",
    "n_noun_classes = model_options.n_noun_classes\n",
    "\n",
    "input_fn = reader.get_input_fn(reader_options, is_training=False)\n",
    "model_fn = trainer.create_model_fn(pipeline_proto)\n",
    "\n",
    "features, labels = input_fn().make_one_shot_iterator().get_next()\n",
    "predictions = model_fn(features, labels, tf.estimator.ModeKeys.PREDICT, None).predictions\n",
    "\n",
    "def data_generator():\n",
    "  saver = tf.train.Saver()\n",
    "  with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    while True:\n",
    "      yield sess.run([predictions, labels])\n",
    "\n",
    "dg = data_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_id_to_name(file_name):\n",
    "  df = pd.read_csv(file_name)\n",
    "  return {i + 1: v for i, v in zip(df['id'], df['key'])}\n",
    "\n",
    "classid2verb = load_id_to_name(verb_classes_csv)\n",
    "classid2noun = load_id_to_name(noun_classes_csv)\n",
    "classid2action = {}\n",
    "for vid, verb in classid2verb.items():\n",
    "  for nid, noun in classid2noun.items():\n",
    "    classid2action[vid * (1 + n_noun_classes) + nid] = verb + ' ' + noun\n",
    "    \n",
    "elem = next(dg)\n",
    "y_pred, y_true = elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from matplotlib import colors\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque', 'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan', 'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet', 'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod', 'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue', 'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue', 'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid', 'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin', 'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed', 'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown', 'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow', 'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n",
    "random.seed(286)\n",
    "random.shuffle(STANDARD_COLORS)\n",
    "STANDARD_COLORS = ['White'] + STANDARD_COLORS\n",
    "\n",
    "def show_color_bar(data, classid2colorid, classid2name, title, show_ticks=True):\n",
    "  observation_window = data.shape[0]\n",
    "    \n",
    "  image = np.full((2, observation_window, 3), 255)\n",
    "  for i in range(observation_window):\n",
    "    color_id = classid2colorid[data[i]]\n",
    "    r, g, b = colors.to_rgb(STANDARD_COLORS[color_id % len(STANDARD_COLORS)].lower())\n",
    "    image[:, i, 0] = int(r * 255)\n",
    "    image[:, i, 1] = int(g * 255)\n",
    "    image[:, i, 2] = int(b * 255)\n",
    "    \n",
    "  plt.figure(figsize=(20, 2))\n",
    "  ax = plt.subplot(111)\n",
    "  ax.tick_params(direction='out', length=0, width=0, colors='black', grid_color='black', grid_alpha=0, labelsize=12)\n",
    "  ax.matshow(image)\n",
    "  if show_ticks:\n",
    "    ticks = [classid2name.get(x, '') + '({})'.format(x) for x in data[:observation_window]]\n",
    "    new_ticks = [ticks[i].split('(')[0] if (i == 0 or ticks[i] != ticks[i - 1]) and ticks[i] != '(0)' else '' for i in range(len(ticks))]\n",
    "    ax.set_xticks(np.arange(observation_window))\n",
    "    ax.set_xticklabels(new_ticks)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticklabels([])\n",
    "  plt.title(title)\n",
    "  plt.xticks(rotation=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_video_length(video_id):\n",
    "  df = pd.read_csv(reader_options.ek100_st_reader.path_to_video_lengths)\n",
    "  df = df[df.video_id == video_id]\n",
    "  return df.to_numpy()[0, 1]\n",
    "\n",
    "def _timestamp_to_seconds(timestamp):\n",
    "  _MINUTES_TO_SECONDS = 60\n",
    "  _HOURS_TO_SECONDS = 60 * 60\n",
    "  hours, minutes, seconds = map(float, timestamp.split(\":\"))\n",
    "  total_seconds = hours * _HOURS_TO_SECONDS + minutes * _MINUTES_TO_SECONDS + seconds\n",
    "  return total_seconds\n",
    "\n",
    "def _read_annotations(video_id):\n",
    "  df = pd.read_pickle(reader_options.ek100_st_reader.path_to_annotations)\n",
    "  df = pd.DataFrame({\n",
    "    'video_id': df['video_id'],\n",
    "    't_start': df['start_timestamp'].apply(_timestamp_to_seconds),\n",
    "    't_end': df['stop_timestamp'].apply(_timestamp_to_seconds),\n",
    "    'verb_class': df['verb_class'],\n",
    "    'noun_class': df['noun_class'],\n",
    "  })\n",
    "  df = df[df.video_id == video_id]\n",
    "  return df\n",
    "\n",
    "video_id = y_pred['video_id'][0].decode('ascii')\n",
    "video_length = _read_video_length(video_id)\n",
    "\n",
    "# Frame-level predictions.\n",
    "verb_seq_logits = y_pred['verb_seq_classification'][0]\n",
    "noun_seq_logits = y_pred['noun_seq_classification'][0]\n",
    "verb_seq_predictions = verb_seq_logits.argmax(-1)\n",
    "noun_seq_predictions = noun_seq_logits.argmax(-1)\n",
    "observation_window = verb_seq_logits.shape[0]\n",
    "\n",
    "# Frame-level labels.\n",
    "annotations = _read_annotations(video_id)\n",
    "verb_seq_labels = np.full((observation_window,), -1, dtype=np.int32)\n",
    "noun_seq_labels = np.full((observation_window,), -1, dtype=np.int32)\n",
    "for _, row in annotations.iterrows():\n",
    "  i_start = int(observation_window * row['t_start'] / video_length)\n",
    "  i_end = int(observation_window * row['t_end'] / video_length)\n",
    "  for i in range(i_start, min(i_end + 1, observation_window)):\n",
    "    verb_seq_labels[i] = row['verb_class']\n",
    "    noun_seq_labels[i] = row['noun_class']\n",
    "verb_seq_labels += 1\n",
    "noun_seq_labels += 1\n",
    "print('video_id = %s, video_length = %.2lf, observation_window = %i' \n",
    "      % (video_id, video_length, observation_window))\n",
    "\n",
    "action_seq_labels = verb_seq_labels * (1 + n_noun_classes) + noun_seq_labels\n",
    "action_seq_predictions = verb_seq_predictions * (1 + n_noun_classes) + noun_seq_predictions\n",
    "actionid2colorid = {c: i for i, c in enumerate(sorted(set(action_seq_labels.tolist() + action_seq_predictions.tolist())))}\n",
    "show_color_bar(action_seq_labels[:100], actionid2colorid, classid2action, \"action GT\")\n",
    "show_color_bar(action_seq_predictions[:100], actionid2colorid, classid2action, \"top-1 action prediction\")\n",
    "\n",
    "# verbid2colorid = {c: i for i, c in enumerate(sorted(set(verb_seq_labels.tolist() + verb_seq_predictions.tolist())))}\n",
    "# show_color_bar(verb_seq_labels[:100], verbid2colorid, classid2verb, \"verb-true\")\n",
    "# show_color_bar(verb_seq_predictions[:100], verbid2colorid, classid2verb, \"verb-pred\")\n",
    "\n",
    "# nounid2colorid = {c: i for i, c in enumerate(sorted(set(noun_seq_labels.tolist() + noun_seq_predictions.tolist())))}\n",
    "# show_color_bar(noun_seq_labels[:100], nounid2colorid, classid2noun, \"noun-true\")\n",
    "# show_color_bar(noun_seq_predictions[:100], nounid2colorid, classid2noun, \"noun-pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_color_bar(action_seq_labels[:100], actionid2colorid, classid2action, \"action GT\")\n",
    "\n",
    "from models.post_process import py_post_process\n",
    "\n",
    "verb_seq_scores = softmax(verb_seq_logits, -1)[:, 1:]\n",
    "noun_seq_scores = softmax(noun_seq_logits, -1)[:, 1:]\n",
    "verb_seq_scores = np.expand_dims(verb_seq_scores, 2)\n",
    "noun_seq_scores = np.expand_dims(noun_seq_scores, 1)\n",
    "action_seq_scores = (verb_seq_scores * noun_seq_scores).reshape([-1, n_verb_classes * n_noun_classes])\n",
    "\n",
    "(i_starts, i_ends, action_ids, action_scores\n",
    " ) = py_post_process(action_seq_scores[:100, :], \n",
    "                     max_n_detection=20, \n",
    "                     thresholds=[x ** 2 for x in [0.1, 0.2, 0.4]])\n",
    "\n",
    "\n",
    "images = []\n",
    "for i_start, i_end, action_id, action_score in zip(i_starts, i_ends, action_ids, action_scores):\n",
    "  verb_id = action_id // n_noun_classes + 1\n",
    "  noun_id = action_id % n_noun_classes + 1\n",
    "  print('%s %s' % (classid2verb[verb_id], classid2noun[noun_id]))\n",
    "\n",
    "  action_id = verb_id * (1 + n_noun_classes) + noun_id\n",
    "#   if not action_id in actionid2colorid: continue\n",
    "        \n",
    "  color_id = actionid2colorid[action_id]\n",
    "  image = np.full((2, 100, 3), 255)\n",
    "  r, g, b = colors.to_rgb(STANDARD_COLORS[color_id % len(STANDARD_COLORS)].lower())\n",
    "  for i in range(i_start, 1 + i_end):\n",
    "    image[:, i, 0] = int(r * 255)\n",
    "    image[:, i, 1] = int(g * 255)\n",
    "    image[:, i, 2] = int(b * 255)\n",
    "  images.append(image)\n",
    "\n",
    "image = np.concatenate(images, 0)\n",
    "plt.figure(figsize=(20, 75))\n",
    "ax = plt.subplot(111)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.matshow(image[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
